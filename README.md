# Fineâ€‘Tuning DistilBERT with LoRA for Sentence Classification

This repository demonstrates how to fineâ€‘tune **DistilBERT** using **LoRA (Lowâ€‘Rank Adaptation)** for a **sentenceâ€‘classification task**.  
LoRA injects small trainable matrices into the model, allowing efficient fineâ€‘tuning with **fewer parameters**, **lower memory usage**, and **faster training**.

---

## ðŸš€ Features

- Fineâ€‘tune DistilBERT using **LoRA adapters**
- Train on any sentenceâ€‘classification dataset (binary or multiâ€‘class)
- Hugging Face `transformers` + `peft` integration
- GPUâ€‘friendly and memoryâ€‘efficient
- Export LoRA weights separately or merge them into the base model
- Inference script included

---
